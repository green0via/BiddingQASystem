{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf99560-2b17-40a0-864e-eaa66f33fb2f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6358fd6b-8324-421a-b207-32d8a12f43cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\eval\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\eval\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-10 16:31:26,092 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: D:\\modelscope\\models\\Qwen\\Qwen3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 16:31:27,533 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: D:\\modelscope\\models\\Qwen\\Qwen3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 5/5 [00:16<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from modelscope import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = 'Qwen/Qwen3-8B'\n",
    "# model_id = 'Qwen/Qwen3-0.6B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype=torch.float16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5977bae5-8601-45b2-be6c-c029918b6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def qwen_llm(prompt):\n",
    "#     inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "#     outputs = model.generate(**inputs, max_new_tokens=32768)\n",
    "#     return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def qwen_llm(prompt_str: str) -> str:\n",
    "    print(\"Qwen...\")\n",
    "    if hasattr(prompt_str, 'to_string'):\n",
    "        prompt_str = prompt_str.to_string()\n",
    "    # ✅ 确保输入是字符串\n",
    "    assert isinstance(prompt_str, str), f\"Expected string, got {type(prompt_str)}\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_str}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=True\n",
    "        )\n",
    "    inputs = tokenizer([text], return_tensors='pt').to(qwen_model.device)\n",
    "    outputs = qwen_model.generate(**inputs, max_new_tokens=32768)  \n",
    "    # return tokenizer.decode(outputs[0], skip_special_tokens=True).split('<think>\\n\\n</think>\\n\\n')[-1]\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67a466e-c6a6-402e-824e-71ea8d40c8be",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7017eb5-cbfd-405d-af26-3a8104e8bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "col_name = \"AllBiddings\"\n",
    "\n",
    "col = Collection(col_name)\n",
    "col.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13452ca8-0d79-4003-80f5-a4f4e321ec54",
   "metadata": {},
   "source": [
    "## Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793fd1ad-61bf-49fa-b3d4-eb7c44030e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|███████████████████████████████████████████████████████████████████████| 30/30 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',\n",
    "                      use_fp16=False,\n",
    "                      pooling_method='cls',\n",
    "                      devices=['cuda:0'])\n",
    "\n",
    "def get_embeddings(text):\n",
    "    embeddings = model.encode(\n",
    "        text,\n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=False\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1fab10-6986-4f20-a60b-76e0f639c5ae",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e18abf2b-81b6-442a-a2bb-cf17bfc00307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import AnnSearchRequest, WeightedRanker\n",
    "\n",
    "def hybrid_search(\n",
    "    col,\n",
    "    query_dense_embedding,\n",
    "    query_sparse_embedding,\n",
    "    sparse_weight=1.0,\n",
    "    dense_weight=1.0,\n",
    "    limit=5,\n",
    "):\n",
    "    print(\"Searching...\")\n",
    "    dense_req = AnnSearchRequest(\n",
    "        [query_dense_embedding], \"dense_vector\", {\"metric_type\": \"L2\", \"params\": {}}, limit=limit\n",
    "    )\n",
    "    sparse_req = AnnSearchRequest(\n",
    "        [query_sparse_embedding], \"sparse_vector\", {\"metric_type\": \"IP\", \"params\": {}}, limit=limit\n",
    "    )\n",
    "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
    "    res = col.hybrid_search(\n",
    "        [sparse_req, dense_req],\n",
    "        rerank=rerank,\n",
    "        limit=limit,\n",
    "        output_fields=[\"text\"]\n",
    "    )\n",
    "    return [\n",
    "        {\"text\": hit.entity.get(\"text\")}\n",
    "        for hit in res[0]\n",
    "    ]\n",
    "\n",
    "def hybrid_search_pipeline(query):\n",
    "    # 在这里调用你的 embedding 模型（比如 bge-m3）\n",
    "    print(\"Embedding...\")\n",
    "    query_embeddings = get_embeddings([query])\n",
    "    query_dense_embeddings = query_embeddings['dense_vecs'][0]\n",
    "    query_sparse_embeddings = query_embeddings.get('lexical_weights')[0]\n",
    "\n",
    "    # 调用原始的搜索方法\n",
    "    return hybrid_search(\n",
    "        col,\n",
    "        query_dense_embeddings,\n",
    "        query_sparse_embeddings,\n",
    "        sparse_weight=1.0,\n",
    "        dense_weight=1.0,\n",
    "        limit=50\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997e365-4a55-4eb6-8ba2-d2a1767b928f",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0eb23d-ab68-49f0-97e6-696eb82fdcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "\n",
    "bge_rf = BGERerankFunction(\n",
    "    model_name=\"BAAI/bge-reranker-v2-m3\",  # Specify the model name. Defaults to `BAAI/bge-reranker-v2-m3`.\n",
    "    device=\"cuda:0\" # Specify the device to use, e.g., 'cpu' or 'cuda:0'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0f42e5-738a-4513-a37e-a178be5251d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(results):\n",
    "    print(\"Reranking...\")\n",
    "    documents = [p['text'] for p in results]\n",
    "    rerank_results = bge_rf(query=query, documents=documents, top_k=1)\n",
    "    return rerank_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92806c-0daf-4d22-8b84-7d853088cffb",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beff761e-c431-4a8b-b558-f8177fca13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
    "If users ask logical question rather than contexual question, you 'd better provide the url of project to avoid protential mistake.\n",
    "If the question is an inference question, you need to inferent step by step.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible. \n",
    "At last you may remind user to get more info from provided url.\n",
    "Answer in Chinese.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "# Create a PromptTemplate instance with the defined template and input variables\n",
    "prompt = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to format the retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.text for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d48f41e-292f-45b5-b20e-7af903399528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "context_chain = RunnableLambda(hybrid_search_pipeline) | RunnableLambda(rerank) | RunnableLambda(format_docs)\n",
    "llm = RunnableLambda(qwen_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cefac7-2c87-4ce9-9f84-5c54f72f8dd1",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b1b5dc-dda6-4895-b5d9-d792d0151d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  最新三条政府采购信息是什么？\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your search query: \")\n",
    "# query_embeddings = get_embeddings([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b77cd7c-f547-42f9-8efc-d409789c928b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding...\n",
      "Searching...\n",
      "Reranking...\n",
      "Qwen...\n",
      "user\n",
      "\n",
      "Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
      "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
      "If users ask logical question rather than contexual question, you 'd better provide the url of project to avoid protential mistake.\n",
      "If the question is an inference question, you need to inferent step by step.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "<context>\n",
      "项目编号：310107000250320195232-07224789。公告标题：采购悦心亭心理服务亭软件三期项目的中标（成交）结果公告。项目名称：采购悦心亭心理服务亭软件三期项目。采购项目子编号：1。标项名称：采购悦心亭心理服务亭软件三期项目。代理机构名称：上海市普陀区政府采购中心。代理机构代码：12310107764741781B。中标金额：1630000.00。中标供应商名称：上海园成医疗器械有限公司。中标供应商地址：上海市宝山区逸仙路2816号1幢9层A0902室。得分：85.27。链接：https://www.shggzy.com/jyxxzcgs/8231765?cExt=eyJhbGciOiJIUzI1NiJ9.eyJwYXRoIjoiL2p5eHh6YyIsInBhZ2VObyI6MSwiZXhwIjoxNzQ4MjY1NzgwMTIzfQ.U0z7uqmiYYh_loqBm8V-z4zQw1USwzE6x8KWrq-Ihxo&amp;isIndex=。爬取时间：nan。\n",
      "\n",
      "项目编号：310104000241128151994-04183976。公告标题：上海市徐汇区政府采购中心——上海市徐汇区卫生事业管理发展中心三江路物业管理服务政府采购项目的中标（成交）结果公告。项目名称：上海市徐汇区政府采购中心——上海市徐汇区卫生事业管理发展中心三江路物业管理服务政府采购项目。采购项目子编号：1。标项名称：上海市徐汇区卫生事业管理发展中心三江路物业管理服务。代理机构名称：徐汇区政府采购中心。代理机构代码：123101044251161729。中标金额：4480920.00。中标供应商名称：上海汇成物业有限公司。中标供应商地址：徐汇区漕东支路81号。得分：93.3。链接：https://www.shggzy.com/jyxxzcgs/8210440?cExt=eyJhbGciOiJIUzI1NiJ9.eyJwYXRoIjoiL2p5eHh6YyIsInBhZ2VObyI6MSwiZXhwIjoxNzQ4MjY1NzgwMTIzfQ.U0z7uqmiYYh_loqBm8V-z4zQw1USwzE6x8KWrq-Ihxo&amp;isIndex=。爬取时间：nan。\n",
      "\n",
      "项目编号：310113000250110159503-13185605。公告标题：政府购买服务人员经费的中标（成交）结果公告。项目名称：政府购买服务人员经费。采购项目子编号：1。标项名称：政府购买服务人员经费。代理机构名称：上海瑞和工程咨询有限公司。代理机构代码：913101137575954641。中标金额：4349960.92。中标供应商名称：上海博霖人力资源有限公司。中标供应商地址：上海市宝山区宝安公路857号博霖科创人才产业园。得分：90.32。链接：https://www.shggzy.com/jyxxzcgs/8216029?cExt=eyJhbGciOiJIUzI1NiJ9.eyJwYXRoIjoiL2p5eHh6YyIsInBhZ2VObyI6MSwiZXhwIjoxNzQ4MjY1NzgwMTIzfQ.U0z7uqmiYYh_loqBm8V-z4zQw1USwzE6x8KWrq-Ihxo&amp;isIndex=。爬取时间：nan。\n",
      "\n",
      "项目编号：310000000241223157018-00191858。公告标题：“三区三线”实施监测评估和动态维护的中标（成交）结果公告。项目名称：“三区三线”实施监测评估和动态维护。采购项目子编号：1。标项名称：“三区三线”实施监测评估和动态维护。代理机构名称：上海财瑞建设管理有限公司。代理机构代码：91310114324590721Q。中标金额：1642500.00。中标供应商名称：上海市自然资源调查利用研究院。中标供应商地址：上海市静安区灵石路930号地质大厦。得分：90.64。链接：https://www.shggzy.com/jyxxzcgs/8184862?cExt=eyJhbGciOiJIUzI1NiJ9.eyJwYXRoIjoiL2p5eHh6YyIsInBhZ2VObyI6MSwiZXhwIjoxNzQ4MjY4MTc3NzA3fQ.BJ3H_Uuc2XZyGIr_S_qvIM45BwARcJSiwG5_It6sFsE&amp;isIndex=。爬取时间：nan。\n",
      "\n",
      "项目编号：310000000241111146101-00182451。公告标题：上海市电动自行车全链条安全监管信息子系统建设项目的中标（成交）结果公告。项目名称：上海市电动自行车全链条安全监管信息子系统建设项目。采购项目子编号：1。标项名称：上海市电动自行车全链条安全监管信息子系统建设项目。代理机构名称：上海市政府采购中心。代理机构代码：12310000425203938B。中标金额：3624000.00。中标供应商名称：上海市大数据股份有限公司。中标供应商地址：上海上海市静安区江场三路228号409室。得分：93.33。链接：https://www.shggzy.com/jyxxzcgs/8165624?cExt=eyJhbGciOiJIUzI1NiJ9.eyJwYXRoIjoiL2p5eHh6YyIsInBhZ2VObyI6MSwiZXhwIjoxNzQ4MjgwNTk5Nzc0fQ.0KOTrZZSrMdGtVYcYhYTBiOlPM0kmGdefKTRxABKoTM&amp;isIndex=。爬取时间：nan。\n",
      "</context>\n",
      "\n",
      "<question>\n",
      "最新三条政府采购信息是什么？\n",
      "</question>\n",
      "\n",
      "The response should be specific and use statistics or numbers when possible. \n",
      "At last you may remind user to get more info from provided url.\n",
      "Answer in Chinese.\n",
      "\n",
      "Assistant:\n",
      "assistant\n",
      "<think>\n",
      "好的，我需要回答用户的问题：“最新三条政府采购信息是什么？”首先，我需要仔细查看提供的上下文中的项目信息，确定哪些是最近的。\n",
      "\n",
      "首先，用户提供的上下文中有五个项目，每个项目都有不同的项目编号和爬取时间。注意到所有项目的爬取时间都是“nan”，这可能表示数据缺失或未记录。不过，可能用户认为这些项目是按时间顺序排列的，或者根据项目编号的某些部分来判断时间。\n",
      "\n",
      "项目编号的格式看起来是“310107000250320195232-07224789”这样的结构，可能前半部分是年份或其他时间相关的信息。例如，第一个项目的项目编号是310107000250320195232，其中可能包含年份“2019”，但后面的项目编号如310104000241128151994可能包含“2015”或“2019”？需要仔细检查每个项目编号的日期部分。\n",
      "\n",
      "不过，可能更简单的方法是按上下文中的顺序来判断，因为用户可能将最新的放在最后。例如，第五个项目是“上海市电动自行车全链条安全监管信息子系统建设项目”，项目编号为310000000241111146101-00182451，可能日期较新。同样，第四个项目是“三区三线”项目，编号为310000000241223157018-00191858，第三个项目是政府购买服务人员经费，编号为310113000250110159503-13185605，第二个是徐汇区的物业管理服务，编号为310104000241128151994-04183976，第一个是悦心亭心理服务亭软件项目，编号为310107000250320195232-07224789。\n",
      "\n",
      "但项目编号中的日期部分可能需要解析。例如，项目编号中的前几位数字可能代表年份。例如，第一个项目编号310107000250320195232，其中“2019”可能出现在某个位置，但不确定。或者可能项目编号中的后几位数字代表年份，比如“320195232”中的“2019”？这可能不太准确。由于时间解析困难，可能需要假设上下文中的顺序即为时间顺序，即最后三个项目是最近的。\n",
      "\n",
      "因此，最新的三条政府采购信息应该是：\n",
      "\n",
      "1. 上海市电动自行车全链条安全监管信息子系统建设项目，中标金额3624000.00，中标供应商是上海市大数据股份有限公司。\n",
      "2. “三区三线”实施监测评估和动态维护项目，中标金额1642500.00，中标供应商是上海市自然资源调查利用研究院。\n",
      "3. 政府购买服务人员经费项目，中标金额4349960.92，中标供应商是上海博霖人力资源有限公司。\n",
      "\n",
      "需要确认这些是否确实是最新，但由于爬取时间都是nan，可能无法准确判断，但根据上下文的排列顺序，最后三个可能是最近的。另外，用户可能需要通过提供的链接获取更多信息，因此最后提醒用户查看链接。\n",
      "</think>\n",
      "\n",
      "根据提供的上下文信息，最新的三条政府采购信息如下：  \n",
      "\n",
      "1. **上海市电动自行车全链条安全监管信息子系统建设项目**  \n",
      "   - 中标金额：3,624,000.00元  \n",
      "   - 中标供应商：上海市大数据股份有限公司  \n",
      "   - 项目链接：[点击查看](https://www.shggzy.com/jyxxzcgs/8165624)  \n",
      "\n",
      "2. **“三区三线”实施监测评估和动态维护项目**  \n",
      "   - 中标金额：1,642,500.00元  \n",
      "   - 中标供应商：上海市自然资源调查利用研究院  \n",
      "   - 项目链接：[点击查看](https://www.shggzy.com/jyxxzcgs/8184862)  \n",
      "\n",
      "3. **政府购买服务人员经费项目**  \n",
      "   - 中标金额：4,349,960.92元  \n",
      "   - 中标供应商：上海博霖人力资源有限公司  \n",
      "   - 项目链接：[点击查看](https://www.shggzy.com/jyxxzcgs/8216029)  \n",
      "\n",
      "以上信息按上下文排列顺序提取，具体时间需以公告原文为准。建议通过提供的链接获取更详细内容。"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": context_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "# res = rag_chain.invoke(query)\n",
    "# res\n",
    "for s in rag_chain.stream(query):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e24e17b4-f356-43aa-8bbc-74d33b5aa476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyC_Zr5GS7vQNxOP8UNHeuPteCWHMR8QlVI\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8143c-3c9c-4894-940c-41e50ada379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def doc_text_formatting(query, docs):\n",
    "    query_words = list(set(jieba.lcut(query)))  # 中文分词\n",
    "    formatted_texts = []\n",
    "\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            highlighted = doc.get('text')\n",
    "        except:\n",
    "            highlighted = doc.text\n",
    "        for word in query_words:\n",
    "            if not word.strip():\n",
    "                continue\n",
    "            highlighted = re.sub(\n",
    "                re.escape(word),\n",
    "                f\"<span style='color:red'>{word}</span>\",\n",
    "                highlighted\n",
    "            )\n",
    "        formatted_texts.append(highlighted)\n",
    "    return formatted_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2047a-dbf4-4dca-bda0-8bf3fd920aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dense_embeddings = query_embeddings['dense_vecs']\n",
    "query_sparse_embeddings = query_embeddings.get('lexical_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fca140-8b46-48cd-93ab-139247da987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_results = hybrid_search(\n",
    "        col,\n",
    "        query_dense_embeddings[0],\n",
    "        query_sparse_embeddings[0],\n",
    "        sparse_weight=1.0,\n",
    "        dense_weight=1.0,\n",
    "        limit=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f1336-5841-4d7d-9961-e18a29c3c1eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(\"### 🔄 **Hybrid Search Results:**\"))\n",
    "formatted_results = doc_text_formatting(query, hybrid_results)\n",
    "for i, result in enumerate(formatted_results):\n",
    "    display(Markdown(f\"para_id: {hybrid_results[i].get('para_id')}\"))\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3d30d-5315-43e3-a9e5-bc44061c62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_rerank_results = rerank(hybrid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9171e59-dfd4-4855-9896-b8e4bb04d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_rerank_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40210c-7373-4d4c-af95-4c13cc2285de",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### 🔄 **Reranked Hybrid Search Results:**\"))\n",
    "formatted_results = doc_text_formatting(query, hybrid_rerank_results)\n",
    "for i, result in enumerate(formatted_results):\n",
    "    display(Markdown(f\"para_id: {hybrid_results[i].get('para_id')}\"))\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff8a0d-cf68-450a-b1bd-806c4c808580",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ebed7-bded-4959-86dc-9ab705fe8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_sub_chain = (\n",
    "    {\"context\": RunnableLambda(hybrid_results) | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc1a54-ded1-42ea-a93b-f78ee97d879a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda-eval] *",
   "language": "python",
   "name": "conda-env-Anaconda-eval-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
