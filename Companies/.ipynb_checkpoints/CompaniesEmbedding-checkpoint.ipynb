{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2853d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "# ✅ 连接 MySQL\n",
    "conn = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"xunfei\",\n",
    "    charset=\"utf8mb4\",\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2d39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 表名与source_type映射\n",
    "table_mapping = {\n",
    "    \"批量查询导出数据（企业信息）\": \"企业\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc88eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_text(record: dict) -> str:\n",
    "    return \"。\".join([f\"{key}：{str(value)}\" for key, value in record.items() if value]) + \"。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f39ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\eval\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\eval\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|███████████████████████████████████████████████████████████████████████| 30/30 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',\n",
    "                      use_fp16=False,\n",
    "                      pooling_method='cls',\n",
    "                      devices=['cuda:0'])\n",
    "\n",
    "def get_embeddings(text):\n",
    "    embeddings = model.encode(\n",
    "        text,\n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=False\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4ab83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"company_id\", dtype=DataType.VARCHAR, max_length=100, is_primary=True),\n",
    "    FieldSchema(name=\"source_type\", dtype=DataType.VARCHAR, max_length=20),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=8192),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=1024),\n",
    "    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"Policy Paragraph Embeddings\")\n",
    "collection_name = \"AllCompanies\"\n",
    "\n",
    "if utility.has_collection(collection_name):\n",
    "    Collection(collection_name).drop()\n",
    "collection = Collection(collection_name, schema, consistency_level=\"Strong\")\n",
    "\n",
    "dense_index = {\"index_type\": \"HNSW\", \"metric_type\": \"L2\"}\n",
    "collection.create_index(\"dense_vector\", dense_index)\n",
    "sparse_inde\n",
    "# col = Collection(col_name)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04e547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取表 批量查询导出数据（企业信息）：632 条\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "向量生成中...: 100%|█████████████████████████████████████████████████████████████████| 632/632 [03:32<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成已完成。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for table_name, source_type in table_mapping.items():\n",
    "    cursor.execute(f\"SELECT * FROM `{table_name}`\")\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"读取表 {table_name}：{len(rows)} 条\")\n",
    "\n",
    "    company_ids = []\n",
    "    source_types = []\n",
    "    texts = []\n",
    "    dense_vectors = []\n",
    "    BATCH_SIZE = 100\n",
    "    \n",
    "    for row in tqdm(rows, desc='向量生成中...'):\n",
    "        text = record_to_text(row).replace('\"', '')\n",
    "        if len(text.encode(\"utf-8\")) > 8192:\n",
    "            continue\n",
    "\n",
    "        # print(text)\n",
    "        # break\n",
    "        company_ids.append(row[\"统一社会信用代码\"])\n",
    "        vector = get_embeddings(text)\n",
    "        dense_vector = vector['dense_vecs']\n",
    "        source_types.append(source_type)\n",
    "        texts.append(text)\n",
    "        dense_vectors.append(dense_vector)\n",
    "        try:\n",
    "            if len(company_ids) > BATCH_SIZE:\n",
    "                collection.insert([company_ids, source_types, texts, dense_vectors])\n",
    "                company_ids = []\n",
    "                source_types = []\n",
    "                texts = []\n",
    "                dense_vectors = []\n",
    "        except:\n",
    "            continue\n",
    "    if source_types:\n",
    "        collection.insert([company_ids, source_types, texts, dense_vectors])\n",
    "\n",
    "print(\"生成已完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1bb4f-9632-41bb-8bed-3609fdabec50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda-eval] *",
   "language": "python",
   "name": "conda-env-Anaconda-eval-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
