{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2853d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\eval\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\eval\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "# ✅ 连接 MySQL\n",
    "conn = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"1234\",\n",
    "    database=\"xunfei\",\n",
    "    charset=\"utf8mb4\",\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2d39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 表名与source_type映射\n",
    "table_mapping = {\n",
    "    \"products\": \"商品\",\n",
    "    \"products2\": \"商品\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc88eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_to_text(record: dict) -> str:\n",
    "    return \"。\".join([f\"{key}：{str(value)}\" for key, value in record.items() if value]) + \"。\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f39ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 30002.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',\n",
    "                      use_fp16=False,\n",
    "                      pooling_method='cls',\n",
    "                      devices=['cuda:0'])\n",
    "\n",
    "def get_embeddings(text):\n",
    "    embeddings = model.encode(\n",
    "        text,\n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=False\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4ab83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"product_id\", dtype=DataType.VARCHAR, max_length=100, is_primary=True),\n",
    "    FieldSchema(name=\"source_type\", dtype=DataType.VARCHAR, max_length=20),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=8192),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=1024)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, description=\"Policy Paragraph Embeddings\")\n",
    "collection_name = \"AllProducts\"\n",
    "\n",
    "if utility.has_collection(collection_name):\n",
    "    Collection(collection_name).drop()\n",
    "collection = Collection(collection_name, schema, consistency_level=\"Strong\")\n",
    "\n",
    "dense_index = {\"index_type\": \"HNSW\", \"metric_type\": \"L2\"}\n",
    "collection.create_index(\"dense_vector\", dense_index)\n",
    "# col = Collection(col_name)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取表 上海政府采购公告：4096 条\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "向量生成中...: 100%|███████████████████████████████████████████████████████████████| 4096/4096 [08:25<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取表 上海政府采购中标结果：4469 条\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "向量生成中...:  11%|███████▎                                                        | 512/4469 [00:41<05:17, 12.47it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "project_id = 1\n",
    "for table_name, source_type in table_mapping.items():\n",
    "    cursor.execute(f\"SELECT * FROM `{table_name}`\")\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"读取表 {table_name}：{len(rows)} 条\")\n",
    "\n",
    "    # batch_data = {\n",
    "    #     # \"project_id\": [],\n",
    "    #     \"source_type\": [],\n",
    "    #     \"text\": [],\n",
    "    #     \"dense_vec\": []\n",
    "    # }\n",
    "    project_ids = []\n",
    "    source_types = []\n",
    "    texts = []\n",
    "    dense_vectors = []\n",
    "    BATCH_SIZE = 100\n",
    "    \n",
    "    for row in tqdm(rows, desc='向量生成中...'):\n",
    "        # if (\"项目编号\" or \"招标项目编号\") not in row or not row[\"项目编号\"]:\n",
    "        #     continue  # 项目编号为空时跳过\n",
    "\n",
    "        text = record_to_text(row).replace('\"', '')\n",
    "        if len(text.encode(\"utf-8\")) > 8192:\n",
    "            continue\n",
    "\n",
    "        # print(text)\n",
    "        # break\n",
    "        product\n",
    "        vector = get_embeddings(text)\n",
    "        dense_vector = vector['dense_vecs']\n",
    "        source_types.append(source_type)\n",
    "        texts.append(text)\n",
    "        dense_vectors.append(dense_vector)\n",
    "        try:\n",
    "            if len(project_ids) > BATCH_SIZE:\n",
    "                collection.insert([project_ids, source_types, texts, dense_vectors])\n",
    "                project_ids = []\n",
    "                source_types = []\n",
    "                texts = []\n",
    "                dense_vectors = []\n",
    "        except:\n",
    "            continue\n",
    "        # batch_data[\"project_id\"].append(row[\"项目编号\"])\n",
    "        # batch_data[\"source_type\"].append(source_type)\n",
    "        # batch_data[\"text\"].append(text)\n",
    "        # batch_data[\"dense_vec\"].append(vector)\n",
    "    if source_types:\n",
    "        collection.insert([project_ids, source_types, texts, dense_vectors])\n",
    "\n",
    "    # 写入 Milvus\n",
    "    # try:\n",
    "    #     if batch_data[\"text\"]:\n",
    "    #         collection.insert([\n",
    "    #             # batch_data[\"project_id\"],\n",
    "    #             batch_data[\"source_type\"],\n",
    "    #             batch_data[\"text\"],\n",
    "    #             batch_data[\"dense_vec\"]\n",
    "    #         ])\n",
    "    #         print(f\"✅ 已写入 {len(batch_data['text'])} 条记录到 Milvus\")\n",
    "    # except:\n",
    "    #     continue\n",
    "\n",
    "\n",
    "# batch_ids = []\n",
    "# para_ids = []\n",
    "# texts = []\n",
    "# dense_vectors = []\n",
    "# sparse_vectors = []\n",
    "# BATCH_SIZE = 100\n",
    "\n",
    "# for doc in tqdm(col_mongo.find({\"vectorized\": True}), desc='向量生成中...'):\n",
    "#     para_id = doc['para_id']\n",
    "#     text = doc['text']\n",
    "#     try:\n",
    "#         vector = get_embeddings(text)\n",
    "#         # print(vector)\n",
    "#         # break\n",
    "#         dense_vector = vector[\"dense_vecs\"]\n",
    "#         sparse_vector = vector[\"lexical_weights\"]\n",
    "#         para_ids.append(para_id)\n",
    "#         texts.append(text)\n",
    "#         dense_vectors.append(dense_vector)\n",
    "#         sparse_vectors.append(sparse_vector)\n",
    "#         batch_ids.append(doc['_id'])\n",
    "#         if len(para_ids) > BATCH_SIZE:\n",
    "#             col.insert([para_ids, texts, dense_vectors, sparse_vectors])\n",
    "#             col_mongo.update_many({\"_id\": {\"$in\": batch_ids}}, {\"$set\": {\"vectorized\": True}})\n",
    "#             batch_ids = []\n",
    "#             para_ids = []\n",
    "#             texts = []\n",
    "#             dense_vectors = []\n",
    "#             sparse_vectors = []\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"向量化失败：{para_id}, {type(e).__name__}: {e}\")\n",
    "\n",
    "    \n",
    "print(\"生成已完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1bb4f-9632-41bb-8bed-3609fdabec50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda-eval] *",
   "language": "python",
   "name": "conda-env-Anaconda-eval-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
